{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습은 로컬로 진행하였습니다.\n",
    "아래의 코드는 완전하지는 않고 흐름 정도만 나타나있습니다.\n",
    "\n",
    "1. label의 데이터를 yolov5가 사용할 수 있는 형태의 txt파일로 만들어준다. ({레이블} {x_center} {y_center} {width} {height} 형태)\n",
    "\n",
    "2. 이미지를 train과 validation으로 나누어 그 정보를 txt파일에 저장한다.\n",
    "\n",
    "3. 레이블과 이미지셋 정보를 담은 yaml파일을 생성한다.\n",
    "\n",
    "4. yaml파일과 yolov5s모델을 통해 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vscha\\Section3\\AI_16_CP1_DS\n"
     ]
    }
   ],
   "source": [
    "# 로컬로 진행하였음\n",
    "%cd C:/Users/vscha/Section3/AI_16_CP1_DS/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 데이터의 json을 txt로 변환\n",
    "json_files = [f for f in os.listdir('.\\data\\json') if f.endswith('.json')]\n",
    "\n",
    "\n",
    "for json_file in json_files:\n",
    "    with open(os.path.join('.\\data\\json', json_file), encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        items = data['FILE'][0]['ITEMS']\n",
    "        img_width, img_height = map(\n",
    "            int, data['FILE'][0]['RESOLUTION'].split(\"*\"))\n",
    "\n",
    "        classes = {'정상차량': 0, '불법차량': 1}\n",
    "\n",
    "        for item in items:\n",
    "            class_name = item[\"PACKAGE\"]\n",
    "            class_id = classes[class_name]\n",
    "\n",
    "            box = item['BOX'].split(',')\n",
    "            x1, y1, x2, y2 = map(float, box)\n",
    "\n",
    "            dw, dh = 1. / img_width, 1. / img_height\n",
    "\n",
    "            x, y, w, h = x1 + x2 / 2.0, y1 + y2 / 2.0, x2, y2\n",
    "\n",
    "            x_center, width = x * dw, w * dw\n",
    "            y_center, height = y * dh, h * dh\n",
    "\n",
    "            yolo_label = f\"{class_id} {x_center} {y_center} {width} {height}\"\n",
    "\n",
    "            filename = os.path.splitext(json_file)[0] + '.txt'\n",
    "            with open(os.path.join('.\\dataset\\labels', filename), 'w') as f:\n",
    "                f.write(yolo_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\dataset\\\\images\\\\A01_B02_C00_D01_0818_E05_F06_159_5.jpg\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미지 리스트를 받아오기\n",
    "def get_image_list(directory):\n",
    "    return [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.jpg')]\n",
    "\n",
    "# 이미지 리스트를 test셋과 val셋으로 나누기\n",
    "def split_data(train_size=0.8):\n",
    "    img_list = get_image_list('./dataset/images')\n",
    "    train_img_list, val_img_list = train_test_split(img_list, test_size=1-train_size)\n",
    "    with open('./dataset/train.txt', 'w') as f:\n",
    "        f.write('\\n'.join(train_img_list) + '\\n')\n",
    "    with open('./dataset/val.txt', 'w') as f:\n",
    "        f.write('\\n'.join(val_img_list) + '\\n')\n",
    "\n",
    "split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블과 데이터에 맞는 yaml파일을 만든 뒤 학습을 진행\n",
    "\n",
    "!python ./models/yolov5/train.py --img 640 --batch 16 --epochs 50 --data ./dataset/data.yaml --cfg ./models/yolov5/models/yolov5s.yaml --weights yolov5.pt --name final_truck_yolov5s_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['./models/yolov5/runs/train/final_truck_yolov5s_results/weights/best.pt'], source=.\\dataset\\images\\A01_B02_C00_D01_0818_E05_F06_344_5.jpg, data=models\\yolov5\\data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=models\\yolov5\\runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5  v7.0-120-g3e55763 Python-3.8.16 torch-1.13.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "image 1/1 C:\\Users\\vscha\\Section3\\AI_16_CP1_DS\\dataset\\images\\A01_B02_C00_D01_0818_E05_F06_344_5.jpg: 384x640 1 legal, 123.0ms\n",
      "Speed: 1.0ms pre-process, 123.0ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mmodels\\yolov5\\runs\\detect\\exp4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "import os\n",
    "\n",
    "# 학습 결과 확인\n",
    "val_img_path = val_img_list[5]\n",
    "\n",
    "!python ./models/yolov5/detect.py --weights ./models/yolov5/runs/train/final_truck_yolov5s_results/weights/best.pt --img 640 --conf 0.5 --source \"{val_img_path}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
